{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb6b76e5",
   "metadata": {},
   "source": [
    "## Temporal evolution of the effective network in the Deffuant opinion dynamics model\n",
    "\n",
    "This notebook contains a detailed implementation of the simulation of the Deffuant Model on arbitrary networks.\n",
    "The words network and graph is used interchangeably. Same applies to node/vertex.\n",
    "\n",
    "#### The first chunk of code defines all the functions needed to run the simulation as well as the implmentation itself.\n",
    "The implmentation relies as much as possible on vectorized operations to yield very good performance.\n",
    "This is true both for the graph analysis library used called graph tool as well as the use of NumPy and SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1733dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool.generation import complete_graph\n",
    "from graph_tool import Graph\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt # https://matplotlib.org/stable/plot_types/basic/plot.html\n",
    "from scipy.sparse import random\n",
    "from scipy.sparse import tril\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from graph_tool.topology import label_components\n",
    "\n",
    "def erdos_renyi(n, p, rng):\n",
    "    \"\"\"\n",
    "    Generates an Erdos-Renyi random graph with n nodes and edge probability p\n",
    "    using a NumPy random number generator.\n",
    "    Returns a NumPy array representing the adjacency matrix of the graph.\n",
    "    \"\"\"\n",
    "    adj_matrix = rng.random((n,n), dtype='float32')\n",
    "    adj_matrix = np.tril(adj_matrix)\n",
    "    adj_matrix += adj_matrix.T\n",
    "    adj_matrix[adj_matrix > p] = 0\n",
    "    adj_matrix[adj_matrix != 0] = 1\n",
    "    np.fill_diagonal(adj_matrix, 0)\n",
    "    return adj_matrix.astype(\"bool\")\n",
    "\n",
    "\n",
    "def erdos_renyi_scipy(n, p, rng):\n",
    "    \"\"\"\n",
    "    Generates an Erdos-Renyi random graph with n nodes and edge probability p\n",
    "    using a NumPy random number generator.\n",
    "    Returns a SciPy sparse matrix representing the adjacency matrix of the graph.\n",
    "    \"\"\"\n",
    "    adj_matrix = random(n, n, density=p, format='csr', dtype=\"bool\", random_state=rng, data_rvs=np.ones)\n",
    "    adj_matrix = tril(adj_matrix)\n",
    "    adj_matrix = adj_matrix + adj_matrix.T\n",
    "    adj_matrix.setdiag(0)\n",
    "    return adj_matrix.astype('bool').toarray()\n",
    "\n",
    "def adj_matrix_to_edge_list(adj_matrix):\n",
    "    \"\"\"\n",
    "    Transforms an adjacency matrix of an undirected graph into a list of edges\n",
    "    \"\"\"\n",
    "    edge_list = np.column_stack(np.where(np.tril(adj_matrix) == 1))\n",
    "    return edge_list\n",
    "\n",
    "def erdos_renyi_graph(n, p, rng):\n",
    "    \"\"\"\n",
    "    Generates an Erdos-Renyi random graph with n nodes and edge probability p\n",
    "    using a NumPy random number generator.\n",
    "    Returns the Erdos-Renyi random graph as a graph_tool Graph.\n",
    "    \"\"\"\n",
    "    e_list = adj_matrix_to_edge_list(erdos_renyi(n=n, p=p, rng=rng))\n",
    "    g = Graph(directed=False)\n",
    "    g.add_edge_list(e_list)\n",
    "    return g\n",
    "\n",
    "def get_random_node_uniform(rng, a_huge_key_list):\n",
    "    \"\"\"\n",
    "    Returns a random uniform entry from a list\n",
    "    \"\"\"\n",
    "    L = len(a_huge_key_list)\n",
    "    i = rng.integers(0, L)\n",
    "    return a_huge_key_list[i]\n",
    "\n",
    "\n",
    "def get_net(net_type, net_order, rng=np.random.default_rng(42), p = None):\n",
    "    \"\"\"\n",
    "    Generates a network of the desired type\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    net_type : str\n",
    "        The desired graph. Currently supports complete graph and erdos renyi random graph\n",
    "    net_order : int\n",
    "        the size of the network\n",
    "    rng : np.random.Generator\n",
    "        A NumPy random number generator\n",
    "    p : float\n",
    "        In the case of erdos renyi graph, the desired edge probability.\n",
    "        If none is specified p is chosen to yield a connected graph \n",
    "        with high proability\n",
    "          \n",
    "    Returns\n",
    "    -------\n",
    "    graph_tool.Graph\n",
    "        A graph of the specified type\n",
    "    \"\"\"\n",
    "    if net_type == 'complete_mixing':\n",
    "        return complete_graph(N=net_order)\n",
    "\n",
    "    elif net_type == 'erdos':\n",
    "        if p == None:\n",
    "            p = ((1+0.001)*np.log(net_order))/net_order \n",
    "            p += 0.001\n",
    "            return erdos_renyi_graph(net_order, p, rng)\n",
    "        return erdos_renyi_graph(net_order, p, rng)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# return all the discussed metrics\n",
    "def metrics(G, components, eff_edges):\n",
    "    \"\"\"\n",
    "    Computes percolation metrics by determing the connected \n",
    "    components of a graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : graph_tool.Graph\n",
    "        The graph on which to compute the metrics.\n",
    "    components : graph_tool.VertexPropertyMap \n",
    "        the connected components at the previous time step\n",
    "    eff_edges : graph_tool.EdgePropertyMap\n",
    "        A boolean array of edges contained in the effective network.    \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    graph_tool.VertexPropertyMap \n",
    "        the connected components at the current time step\n",
    "    float\n",
    "        Fractional size of the largest component\n",
    "    float\n",
    "        Average squared size of non-giant components\n",
    "    \"\"\"\n",
    "    components, sizes = label_components(G, vprop = components, directed = False)\n",
    "    if len(sizes) == 1:\n",
    "        return components, 1, 1, 0\n",
    "    mask = np.ones(sizes.size, dtype=bool)\n",
    "    mask[sizes.argmax()] = False\n",
    "    return components, sizes.max()/sizes.sum(), (sizes[mask]**2).mean()\n",
    "\n",
    "\n",
    "def update_opinions(u, v, opinions, convergence, symmetric_updating=True):\n",
    "    \"\"\"\n",
    "    Updates the opinion of nodes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u : int\n",
    "        The node id of u\n",
    "    v : int\n",
    "        The node id of u's neighbor v\n",
    "    opinions : graph_tool.VertexPropertyMap\n",
    "        An array of opinions.\n",
    "    convergence : float\n",
    "        The value used for updating opinions in the model.\n",
    "    symmetric_updating: bool\n",
    "        If True, at every timestep both nodes update their opinions.\n",
    "        If False, at every timestep only the first selected node updates its opinion.\n",
    "    \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        An array masking nodes outside the confidence bound of u\n",
    "    \"\"\"\n",
    "    #we need to remember to access the array using .a\n",
    "    diff = opinions.a[u] - opinions.a[v]\n",
    "\n",
    "    opinions.a[u] -= convergence * diff\n",
    "    \n",
    "    if symmetric_updating:\n",
    "        opinions.a[v] += convergence * diff\n",
    "        \n",
    "    return opinions.a\n",
    "\n",
    "\n",
    "def effective_neighbors(u, neigh_u, opinions, threshold):\n",
    "    \"\"\"\n",
    "    Finds the neighbors of a node with opinion within confidence bound\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u : int\n",
    "        The node id of u\n",
    "    neigh_u : np.array\n",
    "        An array of edges from u to all its neighbors with edge ids\n",
    "    opinions : graph_tool.VertexPropertyMap\n",
    "        An array of opinions.\n",
    "    threshold : float\n",
    "        Threshold value for node interaction in the model. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        An array masking nodes outside the confidence bound of u\n",
    "    \"\"\"\n",
    "\n",
    "    # neigh_u first column contains u, second neighbor v, third edge index\n",
    "    #compute the updates by indexing the neighbor nodes from opinions and subtracting opinion of u\n",
    "    #this means the len of distances equals number of neighbors of u\n",
    "    distances = opinions.a[neigh_u[:,1]] - opinions.a[u]\n",
    "    \n",
    "    return np.where((distances < -threshold) | (distances > threshold), 0, 1) # filters out non-neighbors with close opinion distance\n",
    "\n",
    "\n",
    "def update_effective_net(u, v, neigh_u, neigh_v, eff_edges, opinions, threshold, symmetric_updating):\n",
    "    \"\"\"\n",
    "    Updates the array of edges in the effective network\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u : int\n",
    "        The node id of u\n",
    "    v : int\n",
    "        The node id of u's neighbor v\n",
    "    neigh_u : np.array\n",
    "        An array of edges from u to all its neighbors with edge ids\n",
    "    neigh_v : np.array\n",
    "        An array of edges from v to all its neighbors with edge ids\n",
    "    eff_edges : graph_tool.EdgePropertyMap\n",
    "        A boolean array of edges contained in the effective network.\n",
    "    threshold : float\n",
    "        Threshold value for node interaction in the model. \n",
    "    symmetric_updating: bool\n",
    "        If True, Noth nodes update their opinions.\n",
    "        If False, only the first selected node updates its opinion.\n",
    "   \n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    eff_edges : graph_tool.EdgePropertyMap\n",
    "        A boolean array of edges contained in the effective network.\n",
    "    \"\"\"\n",
    "    # this gets updates to the effective edges, neighbors has len equalt to number of u's neighbors\n",
    "    neighbors = effective_neighbors(u, neigh_u, opinions, threshold)\n",
    "\n",
    "    #index from the effective edges the edges that form neighbors with u using edge id stored in neigh_u\n",
    "    eff_edges.a[neigh_u[:,-1]]   = neighbors\n",
    "        \n",
    "    if not symmetric_updating:\n",
    "        return eff_edges.a\n",
    "\n",
    "    neighbors = effective_neighbors(v, neigh_v, opinions, threshold)\n",
    "    \n",
    "    eff_edges.a[neigh_v[:,-1]] = neighbors\n",
    "            \n",
    "    return eff_edges.a\n",
    "\n",
    "\n",
    "def simulate_deffuant_model(G: Graph, iterations: int, threshold: float, convergence: float, initial_opinions=None,\\\n",
    "                            symmetric_updating=True, fast_mode=False, rng=np.random.default_rng(42), offset = -1, early_return = False, \\\n",
    "                                check = 1000, res_threshold = 0.001):\n",
    "    \"\"\"\n",
    "    Simulates the Deffuant model on the given graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : graph_tool.Graph\n",
    "        The graph on which to simulate the model.\n",
    "    iterations : int\n",
    "        The  maximum number of iterations to run the simulation for.\n",
    "    threshold : float\n",
    "        Threshold value for node interaction in the model.\n",
    "    convergence : float\n",
    "        The value used for updating opinions in the model.\n",
    "    initial_opinions : np.array\n",
    "        A user specified list of opinions.\n",
    "    symmetric_updating: bool\n",
    "        If True, at every timestep both nodes update their opinions.\n",
    "        If False, at every timestep only the first selected node updates its opinion.\n",
    "    fast_mode: bool\n",
    "        If True, only the metrics of the final effective network is returned and used throughout the simulation.\n",
    "        If False, the metrics of the effective network is saved and returned for every time step.\n",
    "    rng : np.random.Generator\n",
    "        A numpy random number generator.\n",
    "    offset : int\n",
    "        A value to specify the first n numbers are run in fast mode.\n",
    "    early_return : bool\n",
    "        If True, returns the effective network at time step 0\n",
    "    check : int\n",
    "        Check if opinions have converged every K time steps.\n",
    "    res_threshold : float\n",
    "        The resolution threshold to compare the mean absolute difference in opinions between checks.  \n",
    "\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    graph_tool.Graph\n",
    "        A graphs, where each graph represents the state of the network at the final step.\n",
    "    graph_tool.VertexPropertyMap\n",
    "        An array of the final opinions\n",
    "    If fast mode:\n",
    "    graph_tool.VertexPropertyMap\n",
    "        the connected components at the final time step\n",
    "    float\n",
    "        Fractional size of the largest component\n",
    "    float\n",
    "        Average squared size of non-giant components\n",
    "    [float]\n",
    "        A list of the mean absolute difference in opinion.\n",
    "    Else:\n",
    "    [graph_tool.VertexPropertyMap]\n",
    "        A list of the connected components at every time step\n",
    "    [float]\n",
    "        A list of the fractional size of the largest component at every time step\n",
    "    [float]\n",
    "        A list of the Average squared size of non-giant components  at every time step\n",
    "    [float]\n",
    "        A list of the mean absolute difference in opinion\n",
    "    \"\"\"\n",
    "\n",
    "    #Copy the input graph to create the effective graph on which we will compute connected components \n",
    "    G_eff = copy.deepcopy(G)\n",
    "\n",
    "    #Create numpy like arrays \n",
    "    #to store intermediate components\n",
    "    components = G_eff.new_vertex_property('int')\n",
    "    #G_eff.vertex_properties['comp'] = components\n",
    "\n",
    "    # initialize opinions with another numpy like array\n",
    "    opinions = G.new_vertex_property('double')\n",
    "    #G_eff.vertex_properties['ops'] = opinions\n",
    "    \n",
    "    #to store effective edges\n",
    "    eff_edges = G_eff.new_edge_property('bool')\n",
    "    eff_edges.a = True\n",
    "    #apply the effective edges as a filter\n",
    "    G_eff.set_edge_filter(eff_edges)\n",
    "\n",
    "    \n",
    "    if initial_opinions is None:\n",
    "        # .a is used to get the array\n",
    "        opinions.a = rng.random(G.num_vertices(ignore_filter=True))\n",
    "    else:\n",
    "        opinions.a = np.copy(initial_opinions)\n",
    "\n",
    "    for u in G.iter_vertices():\n",
    "        # get all the edges formin neighbors with u\n",
    "        # by setting [G.edge_index] we also get edge ids\n",
    "        # neigh_u first column contains u, second neighbor v, third edge index\n",
    "        neigh_u = G.get_all_edges(u, [G.edge_index])\n",
    "        neighbors = effective_neighbors(u, neigh_u, opinions, threshold)\n",
    "        eff_edges.a[neigh_u[:,-1]]   = neighbors\n",
    "    \n",
    "    #return effective network network after initial setup\n",
    "    if early_return:\n",
    "        return G_eff\n",
    "\n",
    "    if not fast_mode:\n",
    "        # initialize the list results that will be returned\n",
    "        components, dispersion, c_1, avg_sq_clust = metrics(G_eff, components, eff_edges)\n",
    "        dispersions = [dispersion]\n",
    "        c_1s = [c_1]\n",
    "        avg_sq_clusts = [avg_sq_clust]\n",
    "\n",
    "    #Initialize array of previous opinions\n",
    "    opinions_prev = np.copy(opinions.a)\n",
    "    mean_opinion_diff = 0\n",
    "    #Initialize list of mean difference in opinions\n",
    "    opp_diffs = [mean_opinion_diff]\n",
    "\n",
    "    consecutive_checks = 0\n",
    "    # run simulation\n",
    "    for t in np.arange(1, iterations):\n",
    "        \n",
    "        # choose random node to update\n",
    "        u = rng.integers(0, G.num_vertices(ignore_filter=True))\n",
    "        # by setting [eff_edges, G.edge_index] we also get whether edgeis in effective network and edge ids\n",
    "        # neigh_u first column contains u, second neighbors v, third contains a boolean indicating whether\n",
    "        # edge is in effective network, fourth contains edge index\n",
    "        neigh_u = G.get_all_edges(u, [eff_edges, G.edge_index])\n",
    "        \n",
    "        #Check if u is isolated\n",
    "        while not np.any(neigh_u[:,2]):\n",
    "            u = rng.integers(0, G.num_vertices(ignore_filter=True))\n",
    "            neigh_u = G.get_all_edges(u, [eff_edges, G.edge_index])\n",
    "        \n",
    "            \n",
    "\n",
    "        # get a random neighbor of u by chosing from the neighbors that have effective edges\n",
    "        v = rng.choice(neigh_u[neigh_u[:,2]==1,1])\n",
    "        # we don't need effective edges for v\n",
    "        neigh_v = G.get_all_edges(v, [G.edge_index])\n",
    "        \n",
    "        # update their opinions\n",
    "        opinions.a = update_opinions(u, v, opinions, convergence, symmetric_updating)\n",
    "        \n",
    "        if t % check == 0:\n",
    "            #print(f'checking {t}')\n",
    "            mean_opinion_diff = np.abs(opinions_prev-opinions.a).mean()\n",
    "            opp_diffs.append(mean_opinion_diff)\n",
    "            opinions_prev = np.copy(opinions.a)\n",
    "            if mean_opinion_diff < res_threshold:\n",
    "                consecutive_checks += 1\n",
    "                if consecutive_checks >= 2:\n",
    "                    #print(f'checking {t}')\n",
    "                    break\n",
    "            else:\n",
    "                consecutive_checks = 0\n",
    "\n",
    "        \n",
    "        # we now update the connections of these nodes in the effective network depending on\n",
    "        # the opinions of their neighbors in the underlying network G\n",
    "        eff_edges.a = update_effective_net(u, v, neigh_u, neigh_v, eff_edges, opinions, threshold, symmetric_updating)\n",
    "\n",
    "        #offset from fast mode is available to skip connected component on first t trials\n",
    "        if not fast_mode and offset<t:\n",
    "            # add it to list\n",
    "\n",
    "            components, dispersion, c_1, avg_sq_clust = metrics(G_eff, components, eff_edges)\n",
    "            dispersions.append(dispersion)\n",
    "            c_1s.append(c_1)\n",
    "            avg_sq_clusts.append(avg_sq_clust)\n",
    "    \n",
    "    \n",
    "    if fast_mode:\n",
    "        return G_eff, opinions, *metrics(G_eff, components, eff_edges), opp_diffs\n",
    "    else:\n",
    "        return G_eff, opinions, components, c_1s, avg_sq_clusts, opp_diffs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccbc1a92",
   "metadata": {},
   "source": [
    "#### The following code block contains the code for running the simulations across a grid of parameter values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7248314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS for simulating data for plotting\n",
    "\n",
    "# computes the avg value of a metric over a range of d values in a given net type and fixed convergence\n",
    "def metric_d_data(net_type, net_order, symmetric_updating, iterations,\\\n",
    "                       sample_size, num_points, init_d, final_d, convergence, rng, check = 1000, res_threshold = 0.001, p = None):\n",
    "    \"\"\"\n",
    "    Simulates the Deffuant model on the given graph using grid search over values of d.\n",
    "    The function computes the evolution in percolation metrics for a number of d values\n",
    "    using a set sample size.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    net_type : str\n",
    "        A string specifying which model to simulate.\n",
    "    net_order : int\n",
    "        the size of the network\n",
    "    symmetric_updating: bool\n",
    "        If True, at every timestep both nodes update their opinions.\n",
    "        If False, at every timestep only the first selected node updates its opinion.\n",
    "    iterations : int\n",
    "        The maximum number of iterations to run the simulation for.\n",
    "    sample_size : int\n",
    "        The number of points to sample for each value of d\n",
    "    num_points : int\n",
    "        The number of values used from the linear grid\n",
    "    init_d : int\n",
    "        The first d (threshold | confidence bound) value in the grid\n",
    "    final_d : int\n",
    "        The last d value (threshold | confidence bound) in the grid (not included)\n",
    "    convergence : float\n",
    "        The value used for updating opinions in the model.\n",
    "    rng : np.random.Generator\n",
    "        A numpy random number generator.\n",
    "    check : int\n",
    "        Check if opinions have converged every K time steps.\n",
    "    res_threshold : float\n",
    "        The resolution threshold to compare the mean absolute difference in opinions between checks.  \n",
    "    p : float\n",
    "        In the case of erdos renyi graph, the desired edge probability.\n",
    "        If none is specified p is chosen to yield a connected graph \n",
    "        with high proability\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    [np.array float]\n",
    "        A list of arrays of arrays of the mean of the fractional size of the largest component using parameter d from n samples\n",
    "    [np.array float]\n",
    "        A list of arrays of arrays of the variance of the fractional size of the largest component using parameter d from n samples\n",
    "    [np.array float]\n",
    "        A list of arrays of the mean of the Average squared size of non-giant components using parameter d from n samples\n",
    "    [np.array float]\n",
    "        A list of arrays of the variance of the Average squared size of non-giant components using parameter d from n samples\n",
    "    [float]\n",
    "        The grid of d values\n",
    "    \"\"\"\n",
    "    # initialize vector with data\n",
    "    c_1_avgs = []\n",
    "    x_hat_avgs = []\n",
    "    c_1_vars = []\n",
    "    x_hat_vars = []\n",
    "    # initialize vector with x-axis points\n",
    "    d = [init_d + i*(final_d-init_d)/num_points for i in range(num_points)]\n",
    "    \n",
    "    for i in tqdm(range(num_points), desc=\"number of points\"):\n",
    "        #print(\".\", end='') # loading\n",
    "        c_1 = []\n",
    "        x_hat = []\n",
    "        # at every point we will average the metric over sample_size networks\n",
    "        for j in tqdm(range(sample_size),desc=\"samples\"):\n",
    "            \n",
    "            # generate network sample\n",
    "            initial_net = get_net(net_type, net_order, rng, p)\n",
    "\n",
    "            g, ops, comps, C, X, op_dif = simulate_deffuant_model(initial_net, iterations, d[i], convergence,\n",
    "                                                 symmetric_updating=symmetric_updating, fast_mode=False, rng=rng, check = 1000, res_threshold = 0.001)\n",
    "            \n",
    "            # we pad the arrays with the metric values at convergence\n",
    "            C = np.pad(C, (0, iterations-len(X)), 'edge')\n",
    "            X = np.pad(X, (0, iterations-len(X)), 'edge')\n",
    "            c_1.append(C)\n",
    "            x_hat.append(X)\n",
    "\n",
    "        c_1 = np.array(c_1)\n",
    "        x_hat = np.array(x_hat)\n",
    "\n",
    "        c_1_avgs.append(c_1.mean(axis=0))\n",
    "        x_hat_avgs.append(x_hat.mean(axis=0))\n",
    "        c_1_vars.append(c_1.var(axis=0))\n",
    "        x_hat_vars.append(x_hat.var(axis=0))\n",
    "    print()\n",
    "\n",
    "    return c_1_avgs, c_1_vars, x_hat_avgs, x_hat_vars, d\n",
    "\n",
    "\n",
    "# computes the avg value of a metric over a range of d values in a given net type and fixed convergence\n",
    "def metric_mu_data(net_type, net_order, symmetric_updating, iterations,\\\n",
    "                       sample_size, num_points, d, init_mu, final_mu, rng, check = 1000, res_threshold = 0.001, p = None):\n",
    "    \"\"\"\n",
    "    Simulates the Deffuant model on the given graph using grid search over values of d.\n",
    "    The function computes the evolution in percolation metrics for a number of d values\n",
    "    using a set sample size.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    net_type : str\n",
    "        A string specifying which model to simulate.\n",
    "    net_order : int\n",
    "        the size of the network\n",
    "    symmetric_updating: bool\n",
    "        If True, at every timestep both nodes update their opinions.\n",
    "        If False, at every timestep only the first selected node updates its opinion.\n",
    "    iterations : int\n",
    "        The maximum number of iterations to run the simulation for.\n",
    "    sample_size : int\n",
    "        The number of points to sample for each value of mu\n",
    "    num_points : int\n",
    "        The number of values used from the linear grid\n",
    "    d : float\n",
    "        Threshold value for node interaction in the model.\n",
    "    init_mu : int\n",
    "        The first mu (convergence) value in the grid\n",
    "    final_mu : int\n",
    "        The last d value (convergence) in the grid (not included)\n",
    "    rng : np.random.Generator\n",
    "        A numpy random number generator.\n",
    "    check : int\n",
    "        Check if opinions have converged every K time steps.\n",
    "    res_threshold : float\n",
    "        The resolution threshold to compare the mean absolute difference in opinions between checks.  \n",
    "    p : float\n",
    "        In the case of erdos renyi graph, the desired edge probability.\n",
    "        If none is specified p is chosen to yield a connected graph \n",
    "        with high proability\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    [np.array float]\n",
    "        A list of arrays of arrays of the mean of the fractional size of the largest component using parameter mu from n samples\n",
    "    [np.array float]\n",
    "        A list of arrays of arrays of the variance of the fractional size of the largest component using parameter mu from n samples\n",
    "    [np.array float]\n",
    "        A list of arrays of the mean of the Average squared size of non-giant components using parameter mu from n samples\n",
    "    [np.array float]\n",
    "        A list of arrays of the variance of the Average squared size of non-giant components using parameter mu from n samples\n",
    "    [float]\n",
    "        The grid of mu values\n",
    "    \"\"\"\n",
    "    # initialize vector with data\n",
    "    c_1_avgs = []\n",
    "    x_hat_avgs = []\n",
    "    c_1_vars = []\n",
    "    x_hat_vars = []\n",
    "    # initialize vector with x-axis points\n",
    "    mu = [init_mu + i*(final_mu-init_mu)/num_points for i in range(num_points)]\n",
    "    \n",
    "    for i in tqdm(range(num_points), desc=\"number of points\"):\n",
    "        #print(\".\", end='') # loading\n",
    "        c_1 = []\n",
    "        x_hat = []\n",
    "        # at every point we will average the metric over sample_size networks\n",
    "        for j in tqdm(range(sample_size),desc=\"samples\"):\n",
    "            \n",
    "            # generate network sample\n",
    "            initial_net = get_net(net_type, net_order, rng, p)\n",
    "\n",
    "            g, ops, comps, C, X, op_dif = simulate_deffuant_model(initial_net, iterations, d, mu[i],\n",
    "                                                 symmetric_updating=symmetric_updating, fast_mode=False, rng=rng, check = 1000, res_threshold = 0.001)\n",
    "            \n",
    "            # we pad the arrays with the metric values at convergence\n",
    "            C = np.pad(C, (0, iterations-len(X)), 'edge')\n",
    "            X = np.pad(X, (0, iterations-len(X)), 'edge')\n",
    "            c_1.append(C)\n",
    "            x_hat.append(X)\n",
    "\n",
    "        c_1 = np.array(c_1)\n",
    "        x_hat = np.array(x_hat)\n",
    "\n",
    "        c_1_avgs.append(c_1.mean(axis=0))\n",
    "        x_hat_avgs.append(x_hat.mean(axis=0))\n",
    "        c_1_vars.append(c_1.var(axis=0))\n",
    "        x_hat_vars.append(x_hat.var(axis=0))\n",
    "    print()\n",
    "\n",
    "    return c_1_avgs, c_1_vars, x_hat_avgs, x_hat_vars, mu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d11005e",
   "metadata": {},
   "source": [
    "#### In total this note book simulates the Deffuant model over 8 networks\n",
    "\n",
    "We decided to give each experiment its own code block. The simulations below take at max 3 hours. For smaller networks it is very fast."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cbfee02",
   "metadata": {},
   "source": [
    "### Simulating over a grid of d using a complete graph with 1000 nodes\n",
    "We use sample size 10, for 15 points of d between 0.05 and 0.35. Convergence (mu) is fixed to 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd3fe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "c_1_avgs, c_1_vars, x_hat_avgs, x_hat_vars, d = metric_d_data(net_type='complete_mixing', net_order=1000, symmetric_updating=True,\n",
    "                       iterations=250000, sample_size=10, num_points=15, init_d=0.05, final_d=0.35, convergence=0.3, rng=rng, p = 0.05)\n",
    "\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"simulation time: {total_time} seconds\")\n",
    "\n",
    "\n",
    "res = {\"c_1_avgs\" : c_1_avgs, \"c1_vars\" : c_1_vars, \"x_hat_avgs\" : x_hat_avgs, \"x_hat_vars\" : x_hat_vars,\"grid\" : d }\n",
    "\n",
    "with open('results/complete1000_d_005_035_10_15_mu_03.pickle', 'wb') as f:\n",
    "    pickle.dump(res, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "981edf94",
   "metadata": {},
   "source": [
    "### Simulating over a grid of mu using a complete graph with 1000 nodes\n",
    "We use sample size 5, for 10 points of mu between 0.05 and 0.5. Confidence threshold (d) is fixed to 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd3fe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "c_1_avgs, c_1_vars, x_hat_avgs, x_hat_vars, d = metric_mu_data(net_type='complete_mixing', net_order=1000, symmetric_updating=True,\n",
    "                       iterations=250000, sample_size=5, num_points=10, d=0.2, init_mu=0.05, final_mu=0.5, rng=rng, p = 0.05)\n",
    "\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"simulation time: {total_time} seconds\")\n",
    "\n",
    "res = {\"c_1_avgs\" : c_1_avgs, \"c1_vars\" : c_1_vars, \"x_hat_avgs\" : x_hat_avgs, \"x_hat_vars\" : x_hat_vars,\"grid\" : d }\n",
    "\n",
    "with open('results/complete1000_mu_005_05_5_10_d_02.pickle', 'wb') as f:\n",
    "    pickle.dump(res, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "add982d6",
   "metadata": {},
   "source": [
    "### Simulating over a grid of d using a complete graph with 100 nodes\n",
    "We use sample size 20, for 20 points of d between 0.05 and 0.35. Convergence (mu) is fixed to 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd3fe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "c_1_avgs, c_1_vars, x_hat_avgs, x_hat_vars, d = metric_d_data(net_type='complete_mixing', net_order=100, symmetric_updating=True,\n",
    "                       iterations=250000, sample_size=20, num_points=20, init_d=0.05, final_d=0.35, convergence=0.3, rng=rng, p = 0.05)\n",
    "\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"simulation time: {total_time} seconds\")\n",
    "\n",
    "\n",
    "res = {\"c_1_avgs\" : c_1_avgs, \"c1_vars\" : c_1_vars, \"x_hat_avgs\" : x_hat_avgs, \"x_hat_vars\" : x_hat_vars,\"grid\" : d }\n",
    "\n",
    "with open('results/complete100_d_005_035_20_20_mu_03.pickle', 'wb') as f:\n",
    "    pickle.dump(res, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0e4a310",
   "metadata": {},
   "source": [
    "### Simulating over a grid of mu using a complete graph with 100 nodes\n",
    "We use sample size 20, for 10 points of mu between 0.05 and 0.5. Confidence threshold (d) is fixed to 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd3fe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "c_1_avgs, c_1_vars, x_hat_avgs, x_hat_vars, d = metric_mu_data(net_type='complete_mixing', net_order=100, symmetric_updating=True,\n",
    "                       iterations=250000, sample_size=20, num_points=10, d=0.2, init_mu=0.05, final_mu=0.5, rng=rng, p = 0.05)\n",
    "\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"simulation time: {total_time} seconds\")\n",
    "\n",
    "res = {\"c_1_avgs\" : c_1_avgs, \"c1_vars\" : c_1_vars, \"x_hat_avgs\" : x_hat_avgs, \"x_hat_vars\" : x_hat_vars,\"grid\" : d }\n",
    "\n",
    "with open('results/complete100_mu_005_05_20_10_d_02.pickle', 'wb') as f:\n",
    "    pickle.dump(res, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a84381e",
   "metadata": {},
   "source": [
    "### Simulating over a grid of d using an erdos-renyi random graph with 1000 nodes\n",
    "We use sample size 10, for 15 points of d between 0.05 and 0.35. Convergence (mu) is fixed to 0.3.\n",
    "We generate the random graph using edge probability 0.005 which yields connected graphs with high probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd3fe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "c_1_avgs, c_1_vars, x_hat_avgs, x_hat_vars, d = metric_d_data(net_type='erdos', net_order=1000, symmetric_updating=True,\n",
    "                       iterations=250000, sample_size=10, num_points=15, init_d=0.05, final_d=0.35, convergence=0.3, rng=rng, p = 0.005)\n",
    "\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"simulation time: {total_time} seconds\")\n",
    "\n",
    "\n",
    "res = {\"c_1_avgs\" : c_1_avgs, \"c1_vars\" : c_1_vars, \"x_hat_avgs\" : x_hat_avgs, \"x_hat_vars\" : x_hat_vars,\"grid\" : d }\n",
    "\n",
    "with open('results/erdos1000_d_005_035_10_15_mu_03.pickle', 'wb') as f:\n",
    "    pickle.dump(res, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1df0e8d7",
   "metadata": {},
   "source": [
    "### Simulating over a grid of mu using an erdos-renyi random graph with 1000 nodes\n",
    "We use sample size 10, for 20 points of mu between 0.05 and 0.5. Confidence threshold (d) is fixed to 0.15\n",
    "We generate the random graph using edge probability 0.005 which yields connected graphs with high probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd3fe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "c_1_avgs, c_1_vars, x_hat_avgs, x_hat_vars, d = metric_mu_data(net_type='erdos', net_order=1000, symmetric_updating=True,\n",
    "                       iterations=250000, sample_size=10, num_points=20, d=0.15, init_mu=0.05, final_mu=0.5, rng=rng, p = 0.005)\n",
    "\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"simulation time: {total_time} seconds\")\n",
    "\n",
    "res = {\"c_1_avgs\" : c_1_avgs, \"c1_vars\" : c_1_vars, \"x_hat_avgs\" : x_hat_avgs, \"x_hat_vars\" : x_hat_vars,\"grid\" : d }\n",
    "\n",
    "with open('results/erdos1000_mu_005_05_10_20_d_015.pickle', 'wb') as f:\n",
    "    pickle.dump(res, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66694c6d",
   "metadata": {},
   "source": [
    "### Simulating over a grid of d using an erdos-renyi random graph with 100 nodes\n",
    "We use sample size 30, for 15 points of d between 0.05 and 0.35. Convergence (mu) is fixed to 0.3.\n",
    "We generate the random graph using edge probability 0.05 which yields connected graphs with high probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd3fe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "c_1_avgs, c_1_vars, x_hat_avgs, x_hat_vars, d = metric_d_data(net_type='erdos', net_order=100, symmetric_updating=True,\n",
    "                       iterations=250000, sample_size=30, num_points=15, init_d=0.05, final_d=0.35, convergence=0.3, rng=rng, p = 0.05)\n",
    "\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"simulation time: {total_time} seconds\")\n",
    "\n",
    "\n",
    "res = {\"c_1_avgs\" : c_1_avgs, \"c1_vars\" : c_1_vars, \"x_hat_avgs\" : x_hat_avgs, \"x_hat_vars\" : x_hat_vars,\"grid\" : d }\n",
    "\n",
    "with open('results/erdos100_d_005_035_30_15_mu_03.pickle', 'wb') as f:\n",
    "    pickle.dump(res, f)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec3b6984",
   "metadata": {},
   "source": [
    "### Simulating over a grid of mu using an erdos-renyi random graph with 100 nodes\n",
    "We use sample size 10, for 20 points of mu between 0.05 and 0.5. Confidence threshold (d) is fixed to 0.15\n",
    "We generate the random graph using edge probability 0.05 which yields connected graphs with high probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd3fe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "c_1_avgs, c_1_vars, x_hat_avgs, x_hat_vars, d = metric_mu_data(net_type='complete_mixing', net_order=100, symmetric_updating=True,\n",
    "                       iterations=250000, sample_size=20, num_points=20, d=0.2, init_mu=0.05, final_mu=0.5, rng=rng, p = 0.05)\n",
    "\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"simulation time: {total_time} seconds\")\n",
    "\n",
    "res = {\"c_1_avgs\" : c_1_avgs, \"c1_vars\" : c_1_vars, \"x_hat_avgs\" : x_hat_avgs, \"x_hat_vars\" : x_hat_vars,\"grid\" : d }\n",
    "\n",
    "with open('results/erdos100_mu_005_05_20_20_d_015.pickle', 'wb') as f:\n",
    "    pickle.dump(res, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca375214",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c207b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import cm\n",
    "\n",
    "def get_n_colors(n):\n",
    "    return cm.tab20(range(n)).tolist()\n",
    "\n",
    "def plot_multiple_lines(lines, variances, plot_first_n = -1, title=None, xlabel=None, ylabel=None, legends = None, colors = None):\n",
    "    for i, line in enumerate(lines):\n",
    "        y_values = line[:plot_first_n]\n",
    "        variance = variances[i][:plot_first_n]\n",
    "        x_values = np.arange(len(y_values))\n",
    "        if colors:\n",
    "            color = colors[i]\n",
    "        else:\n",
    "            color = None\n",
    "        plt.plot(x_values, y_values, color=color)\n",
    "      # plt.fill_between(x_values, y_values-variance, y_values+variance, color=color, alpha=0.2)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend(legends, loc='center right')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "cols = get_n_colors(len(d))\n",
    "\n",
    "plot_multiple_lines(c_1_avgs, c_1_vars, plot_first_n=100000, legends=[round(x, 2) for x in d], colors=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d83c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_lines(x_hat_avgs, x_hat_vars, plot_first_n=25000, legends=[round(x, 2) for x in d], colors=cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50d4e27f",
   "metadata": {},
   "source": [
    "### Code block for testing implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92df683",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "graph = get_net('complete_mixing', 1000)\n",
    "\n",
    "start = time.time()\n",
    "g, ops, comps, y, C, X, op_dif = simulate_deffuant_model(graph, 250000, 0.2, 0.05, symmetric_updating=True, fast_mode=False, rng=rng, offset=-1, res_threshold=0.001)\n",
    "\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"simulation time: {total_time} seconds in {len(op_dif)}k steps\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56fb688b",
   "metadata": {},
   "source": [
    "### The experiments reported in the paper are over\n",
    "\n",
    "The rest of the notebook contains first a playground for visualizing the output from the previous code block\n",
    "\n",
    "Then follows a number of code blocks used for benchmarking our utility functions from the first code block. It also includes other graph generation approaches. We also tried various methods to improve our main graph algorithm for finding connected components but ended up using the functionality provided by graph tool.\n",
    "Finally there is a very early version of our simulation function built for sparse matrices. However this approach was too inefficient for complete graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15713558",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(op_dif)), op_dif, linewidth=2.0, color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069bd41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ops.a, bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f71fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool import draw\n",
    "draw.graph_draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(X[:])), X[:], linewidth=2.0, color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02e042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(C[:])), C[:], linewidth=2.0, color='green')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6cd43684",
   "metadata": {},
   "source": [
    "##### Graph generation experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ba52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import random\n",
    "from scipy.sparse import tril\n",
    "\n",
    "\n",
    "def erdos_renyi_scipy(n, p, rng):\n",
    "    \"\"\"\n",
    "    Generates an Erdos-Renyi random graph with n nodes and edge probability p.\n",
    "    Returns a SciPy sparse matrix representing the adjacency matrix of the graph.\n",
    "    \"\"\"\n",
    "    adj_matrix = random(n, n, density=p, format='csr', dtype=\"bool\", random_state=rng, data_rvs=np.ones)\n",
    "    adj_matrix = tril(adj_matrix)\n",
    "    adj_matrix = adj_matrix + adj_matrix.T\n",
    "    #adj_matrix.data = np.ones_like(adj_matrix.data)\n",
    "    adj_matrix.setdiag(0)\n",
    "    return adj_matrix.astype('bool').toarray()\n",
    "\n",
    "def erdos_renyi(n, p, rng):\n",
    "    \"\"\"\n",
    "    Generates an Erdos-Renyi random graph with n nodes and edge probability p.\n",
    "    Returns a NumPy array representing the adjacency matrix of the graph.\n",
    "    \"\"\"\n",
    "    adj_matrix = rng.random((n,n), dtype='float32')\n",
    "    adj_matrix = np.tril(adj_matrix)\n",
    "    adj_matrix += adj_matrix.T\n",
    "    adj_matrix[adj_matrix > p] = 0\n",
    "    adj_matrix[adj_matrix != 0] = 1\n",
    "    np.fill_diagonal(adj_matrix, 0)\n",
    "    return adj_matrix.astype(\"bool\")\n",
    "\n",
    "\n",
    "def erdos_renyi_bin(n, p, rng):\n",
    "    \"\"\"\n",
    "    Generates an Erdos-Renyi graph with n nodes and edge probability p, where self-loops are not allowed.\n",
    "    :param n: int, number of nodes in the graph\n",
    "    :param p: float, probability of an edge between any two nodes\n",
    "    :return: numpy array, adjacency matrix of the graph\n",
    "    \"\"\"\n",
    "    adj_matrix = rng.binomial(1, p, size=(n, n))\n",
    "    adj_matrix = np.tril(adj_matrix)\n",
    "    adj_matrix += adj_matrix.T\n",
    "    np.fill_diagonal(adj_matrix, 0)\n",
    "    return adj_matrix.astype('bool')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f69d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "ER_sci = erdos_renyi_scipy(10000, p = 0.001, rng = rng)\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"scipy time: {total_time} seconds\")\n",
    "\n",
    "start = time.time()\n",
    "ER_num = erdos_renyi_graph(10000, p = 0.001, rng = rng)\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"numpy time: {total_time} seconds\")\n",
    "\n",
    "start = time.time()\n",
    "ER_num = erdos_renyi(10000, p = 0.001, rng = rng)\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"numpy time: {total_time} seconds\")\n",
    "\n",
    "print(f\"Scipy size = {ER_sci.data.nbytes} \\n Numpy size = {ER_num.nbytes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede97e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "test = erdos_renyi_scipy(N, 0.001, rng=rng)\n",
    "e_list = adj_matrix_to_edge_list(test)\n",
    "g = Graph(directed=False)\n",
    "g.add_edge_list(e_list)\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"scipy time: {total_time} seconds\")\n",
    "\n",
    "start = time.time()\n",
    "test = erdos_renyi_bin(N, 0.001, rng=rng)\n",
    "e_list = adj_matrix_to_edge_list(test)\n",
    "g = Graph(directed=False)\n",
    "g.add_edge_list(e_list)\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"from binomial time: {total_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e1be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkit as nk\n",
    "import sys\n",
    "from graph_tool.generation import complete_graph\n",
    "from graph_tool import Graph\n",
    "from graph_tool.generation import random_graph\n",
    "\n",
    "import time\n",
    "\n",
    "N = 10000\n",
    "\n",
    "start = time.time()\n",
    "test = erdos_renyi_scipy(N, 0.001, rng=rng)\n",
    "e_list = adj_matrix_to_edge_list(test)\n",
    "g_ = Graph(directed=False)\n",
    "g_.add_edge_list(e_list)\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"numpy time: {total_time} seconds\")\n",
    "\n",
    "def erdos_sample(n, p):\n",
    "    return (np.random.binomial(n, p))\n",
    "\n",
    "start = time.time()\n",
    "g = random_graph(N, lambda: erdos_sample(N, 0.1), directed = False)\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"numpy time: {total_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c925970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "\n",
    "start = time.time()\n",
    "test = complete_adj(N)\n",
    "e_list = adj_matrix_to_edge_list(test)\n",
    "g = Graph(directed=False)\n",
    "g.add_edge_list(e_list)\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"gt time: {total_time} seconds\")\n",
    "\n",
    "start = time.time()\n",
    "g = complete_graph(N)\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"gt time: {total_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool.topology import label_components\n",
    "\n",
    "N=10000\n",
    "\n",
    "g_ = complete_graph(N)\n",
    "\n",
    "start = time.time()\n",
    "_, comp = label_components(g_)\n",
    "total_time = round(time.time()-start, 3)\n",
    "print(f\"gt time: {total_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17072f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "def Reciprocity(adjmatrix):\n",
    "    \"\"\"Computes the fraction of reciprocal links to total number of links.\n",
    "    Both weighted and unweighted input matrices are permitted. Weights\n",
    "    are ignored for the calculation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    adjmatrix : ndarray of rank-2\n",
    "        The adjacency matrix of the network.\n",
    "    Returns\n",
    "    -------\n",
    "    reciprocity : float\n",
    "        A scalar value between 0 (for acyclic directed networks) and 1 (for\n",
    "        fully reciprocal).\n",
    "    \"\"\"\n",
    "    # 0) PREPARE FOR COMPUTATIONS\n",
    "    adjmatrix = adjmatrix.astype('bool')\n",
    "\n",
    "    # 1) COMPUTE THE RECIPROCITY\n",
    "    L = adjmatrix.sum()\n",
    "    if L == 0:\n",
    "        reciprocity = 0\n",
    "    else:\n",
    "        # Find the assymmetric links\n",
    "        # Rest = np.abs(adjmatrix - adjmatrix.T)\n",
    "        Rest = np.abs(adjmatrix ^ adjmatrix.T)\n",
    "        Lsingle = 0.5*Rest.sum()\n",
    "        reciprocity = np.float(L-Lsingle) / L\n",
    "\n",
    "    return reciprocity\n",
    "\n",
    "def FloydWarshall_Numba(adjmatrix, weighted_dist=False):\n",
    "    \"\"\"Computes the pathlength between all pairs of nodes in a network.\n",
    "    WARNING! This version returns the same output as 'FloydWarshall()'\n",
    "        function in main metrics.py module but runs much faster (for networks\n",
    "        of N > 100). It requires package Numba to be installed.\n",
    "    Parameters\n",
    "    ----------\n",
    "    adjmatrix : ndarray of rank-2\n",
    "        The adjacency matrix of the network.\n",
    "    weighted_dist : boolean, optional\n",
    "        If True, if the graph distances are computed considering the weights\n",
    "        of the links. False, otherwise. If 'adjmatrix' is a weighted\n",
    "        network but'weighted_dist = False', the weights of the links are\n",
    "        ignored.\n",
    "    Returns\n",
    "    -------\n",
    "    distmatrix : ndarray of rank-2\n",
    "        The pairwise distance matrix dij of the shortest pathlength between\n",
    "        nodes i and j.\n",
    "    See Also\n",
    "    --------\n",
    "    FloydWarshall : Computes the pathlength between all pairs of nodes.\n",
    "    \"\"\"\n",
    "    # 0) DEFINE THE CORE OF THE FW ALGORITHM, ACCELARATED BY 'Numba'\n",
    "    @jit\n",
    "    def FW_Undirected(distmatrix):\n",
    "        \"\"\"The Floyd-Warshall algorithm for undirected networks\n",
    "        \"\"\"\n",
    "        N = len(distmatrix)\n",
    "        for k in range(N):\n",
    "            for i in range(N):\n",
    "                for j in range(i,N):\n",
    "                    d = distmatrix[i,k] + distmatrix[k,j]\n",
    "                    if distmatrix[i,j] > d:\n",
    "                        distmatrix[i,j] = d\n",
    "                        distmatrix[j,i] = d\n",
    "\n",
    "    @jit\n",
    "    def FW_Directed(distmatrix):\n",
    "        \"\"\"The Floyd-Warshall algorithm for directed networks\n",
    "        \"\"\"\n",
    "        N = len(distmatrix)\n",
    "        for k in range(N):\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    d = distmatrix[i,k] + distmatrix[k,j]\n",
    "                    if distmatrix[i,j] > d:\n",
    "                        distmatrix[i,j] = d\n",
    "\n",
    "    ########################################################################\n",
    "    # 1) PREPARE FOR THE CALCULATIONS\n",
    "    # 1.1) Initialize the distance matrix\n",
    "    if weighted_dist:\n",
    "        distmatrix = np.where(adjmatrix == 0, np.inf, adjmatrix)\n",
    "    else:\n",
    "        distmatrix = np.where(adjmatrix == 0, np.inf, 1)\n",
    "\n",
    "    # 1.2) Find out whether the network is directed or undirected\n",
    "    recip = Reciprocity(adjmatrix)\n",
    "\n",
    "    # 2) RUN THE FLOYD-WARSHALL ALGORITHM USING FASTER FUNCTIONS (NUMBA)\n",
    "    if recip==1.0:\n",
    "        FW_Undirected(distmatrix)\n",
    "    else:\n",
    "        FW_Directed(distmatrix)\n",
    "\n",
    "    return distmatrix\n",
    "\n",
    "def ConnectedComponents(distmatrix, directed=False, showall=True):\n",
    "    \"\"\"Finds all the connected components in a network out of a distance\n",
    "    matrix.\n",
    "    A strongly connected component is a set of nodes for which there is\n",
    "    at least one path connecting every two nodes within the set.\n",
    "    The function works both for directed and undirected networks, provided\n",
    "    the adequate distance matrix is given.\n",
    "    Parameters\n",
    "    ----------\n",
    "    distmatrix : ndarray of rank-2\n",
    "        The pairwise graph distance matrix of the network, usually the\n",
    "        output of function FloydWarshall().\n",
    "    directed : boolean, optional\n",
    "        'True' if the network is directed, 'False' if it is undirected.\n",
    "    showall : boolean, optional\n",
    "        If 'True' the function returns all strong components, including\n",
    "        independent nodes. If 'False' it returns only components of two\n",
    "        or more nodes.\n",
    "    Returns\n",
    "    -------\n",
    "    components : list\n",
    "        A list containing the components as ordered lists of nodes.\n",
    "    See Also\n",
    "    --------\n",
    "    FloydWarshall : Pairwise graph distance between all nodes of a network.\n",
    "    \"\"\"\n",
    "    N = len(distmatrix)\n",
    "\n",
    "    # 1) Detect nodes that are connected in both directions\n",
    "    newmatrix = np.where(distmatrix < N, 1, 0)\n",
    "\n",
    "    # If network is directed, consider only pairs with a reciprocal path\n",
    "    if directed:\n",
    "        newmatrix = newmatrix * newmatrix.T\n",
    "\n",
    "    # 2) Sort the nodes into their components\n",
    "    # nodelist = range(N)\n",
    "    nodelist = np.arange(N).tolist()\n",
    "    components = []\n",
    "    while nodelist:\n",
    "        # Take the first node. This helps keeping the output sorted\n",
    "        node = nodelist[0]\n",
    "        if newmatrix[node,node]:\n",
    "            # Find the component to which the node belongs to\n",
    "            comp = list(newmatrix[node].nonzero()[0])\n",
    "            components.append(comp)\n",
    "            # Remove nodes in comp from nodelist\n",
    "            for neigh in comp:\n",
    "                nodelist.remove(neigh)\n",
    "            # Clean trash\n",
    "            del comp\n",
    "        else:\n",
    "            # The node is independent. Remove from list and continue\n",
    "            if showall:\n",
    "                components.append([node])\n",
    "            nodelist.remove(node)\n",
    "            continue\n",
    "\n",
    "    del newmatrix\n",
    "    return components"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33421a8e",
   "metadata": {},
   "source": [
    "### Following code is a sparse matrix implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def get_random_node_uniform(rng, a_huge_key_list):\n",
    "    L = len(a_huge_key_list)\n",
    "    i = rng.integers(0, L)\n",
    "    return a_huge_key_list[i]\n",
    "\n",
    "def get_net(net_type, net_order, rng=None):\n",
    "    if net_type == 'scale_free':\n",
    "        return nx.barabasi_albert_graph(n=net_order, m=2, seed=rng, initial_graph=nx.complete_graph(3))\n",
    "\n",
    "    elif net_type == 'complete_mixing':\n",
    "        return nx.complete_graph(n=net_order)\n",
    "\n",
    "    elif net_type == 'lattice':\n",
    "        return nx.grid_2d_graph(int(np.sqrt(net_order)), int(np.sqrt(net_order)), periodic=False)\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def update_opinions(u, v, opinions, convergence, symmetric_updating=True):\n",
    "    diff = opinions[u] - opinions[v]\n",
    "\n",
    "    opinions[u] -= convergence * diff\n",
    "    \n",
    "    if symmetric_updating:\n",
    "        opinions[v] += convergence * diff\n",
    "        \n",
    "    return opinions\n",
    "\n",
    "\n",
    "def effective_neighbors(u, adjG, opinions, threshold):\n",
    "    \n",
    "    distances = opinions - opinions[u] # vector of opinion distances\n",
    "    distances[(distances < -threshold) | (distances > threshold)] = -1 # turn nodes at dist>d into -1\n",
    "    distances[distances != -1] = 0 # the rest into 0\n",
    "    distances += 1 # close nodes are now 1 and far away ones are 0\n",
    "    \n",
    "    return adjG[[u],:]*distances # filters out non-neighbors with close opinion distance\n",
    "\n",
    "\n",
    "def update_effective_net(u, v, effective_net, adjG, opinions, threshold, symmetric_updating):\n",
    "    \n",
    "    neighbors = effective_neighbors(u, adjG, opinions, threshold)\n",
    "\n",
    "    effective_net[[u],:]   = neighbors\n",
    "    effective_net[:,[u]] = neighbors.transpose()\n",
    "        \n",
    "    if not symmetric_updating:\n",
    "        return effective_net\n",
    "\n",
    "    neighbors = effective_neighbors(v, adjG, opinions, threshold)\n",
    "    \n",
    "    effective_net[[v],:]   = neighbors\n",
    "    effective_net[:,[v]] = neighbors.transpose()\n",
    "            \n",
    "    return effective_net\n",
    "\n",
    "\n",
    "def simulate_deffuant_model(G: nx.Graph, iterations: int, threshold: float, convergence: float, initial_opinions=None,\\\n",
    "                            symmetric_updating=True, fast_mode=False, rng=np.random.default_rng(42)):\n",
    "    \"\"\"\n",
    "    Simulates the Deffuant model on the given graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : networkx.Graph\n",
    "        The graph on which to simulate the model.\n",
    "    iterations : int\n",
    "        The number of iterations to run the simulation for.\n",
    "    threshold : float\n",
    "        Threshold value for node interaction in the model.\n",
    "    convergence : float\n",
    "        The value used for updating opinions in the model.\n",
    "    symmetric_updating: bool\n",
    "        If True, at every timestep both nodes update their opinions.\n",
    "        If False, at every timestep only the first selected node updates its opinion.\n",
    "    fast_mode: bool\n",
    "        If True, only the last effective network is returned and used throughout the simulation.\n",
    "        If False, every effective network is saved and returned.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[networkx.Graph]\n",
    "        A list of graphs, where each graph represents the state of the network at a given time step.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize opinions\n",
    "    if initial_opinions is None:\n",
    "        opinions = rng.random(G.order())\n",
    "    else:\n",
    "        opinions = np.copy(initial_opinions)\n",
    "    \n",
    "    # save adjacency matrix\n",
    "    adjG = nx.adjacency_matrix(G)\n",
    "\n",
    "    # get initial effective network\n",
    "    effective_net = nx.adjacency_matrix(G)\n",
    "    for u in G.nodes():\n",
    "        # get 0-1 vector of neighbors at opinion distance <threshold\n",
    "        neighbors = effective_neighbors(u, adjG, opinions, threshold)\n",
    "        effective_net[[u],:]   = neighbors\n",
    "        effective_net[:,[u]] = neighbors.transpose()\n",
    "    if not fast_mode:\n",
    "        # initialize the list of nets that will be returned\n",
    "        network_history = [effective_net]\n",
    "        opinion_history = [opinions]\n",
    "\n",
    "    # run simulation\n",
    "    for t in range(1, iterations):\n",
    "        \n",
    "        if not fast_mode:\n",
    "            # copy last effective network\n",
    "            effective_net = np.copy(network_history[t-1])\n",
    "            opinions      = np.copy(opinion_history[t-1])\n",
    "\n",
    "        # choose random node to update\n",
    "        u = rng.choice(G.order())\n",
    "        \n",
    "        # get another node if u is isolated\n",
    "        while not effective_net[[u],:].sum():\n",
    "            u = rng.choice(G.order())\n",
    "        \n",
    "        # get a random neighbor of u\n",
    "        v = get_random_node_uniform(rng, np.argwhere(effective_net[[u]:]==1))[0]\n",
    "\n",
    "        # update their opinions\n",
    "        opinions = update_opinions(u, v, opinions, convergence, symmetric_updating)\n",
    "        \n",
    "        # we now update the connections of these nodes in the effective network depending on\n",
    "        # the opinions of their neighbors in the underlying network G\n",
    "        effective_net = update_effective_net(u, v, effective_net, adjG, opinions, threshold, symmetric_updating)\n",
    "        \n",
    "        if not fast_mode:\n",
    "            # add it to list\n",
    "            network_history.append(effective_net)\n",
    "            opinion_history.append(opinions)\n",
    "    \n",
    "    if fast_mode:\n",
    "        return effective_net, opinions\n",
    "    else:\n",
    "        return network_history, opinion_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csn_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ae9fa0a07edcf115bc02224825ce632072c66e4ec6e031454900b493eddc2b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
